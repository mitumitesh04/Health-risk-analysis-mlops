import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import requests
import json
import numpy as np
from datetime import datetime, timedelta

st.set_page_config(
    page_title="Health Risk MLOps Dashboard",
    page_icon="ü©∫",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #ff4b4b;
    }
    .stTabs [data-baseweb="tab-list"] button [data-testid="stMarkdownContainer"] p {
        font-size: 16px;
    }
</style>
""", unsafe_allow_html=True)

def main():
    st.title("ü©∫ Health Risk MLOps Dashboard")
    st.markdown("**Production-ready health risk prediction system with MLOps capabilities**")
    
    # Sidebar
    with st.sidebar:
        st.markdown("### Navigation")
        
        # API status check
        try:
            response = requests.get("http://localhost:8000/health", timeout=2)
            if response.status_code == 200:
                st.success("üü¢ API Online")
                api_status = response.json()
                st.metric("Predictions Served", api_status.get('predictions_served', 0))
            else:
                st.error("üî¥ API Offline")
                api_status = None
        except:
            st.error("üî¥ API Offline")
            api_status = None
        
        st.markdown("---")
        refresh_data = st.button("üîÑ Refresh Data")
    
    # Main content tabs
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üîÆ Prediction", 
        "üìä Data Analysis", 
        "üìà Model Performance", 
        "üöÄ MLOps Pipeline",
        "üìã System Monitoring"
    ])
    
    with tab1:
        prediction_interface()
    
    with tab2:
        data_analysis_page()
    
    with tab3:
        model_performance_page()
    
    with tab4:
        mlops_pipeline_page()
    
    with tab5:
        system_monitoring_page()

def prediction_interface():
    st.header("üîÆ Health Risk Prediction Interface")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("Patient Information")
        
        with st.form("prediction_form"):
            heart_rate = st.slider("üíì Heart Rate (bpm)", 40, 150, 75, help="Resting heart rate")
            steps_daily = st.slider("üö∂ Daily Steps", 0, 20000, 8000, help="Average daily step count")
            sleep_hours = st.slider("üò¥ Sleep Hours", 3.0, 12.0, 7.5, 0.5, help="Average nightly sleep")
            age = st.slider("üìÖ Age", 18, 100, 35, help="Patient age in years")
            
            submitted = st.form_submit_button("üîç Predict Risk", type="primary")
        
        # Risk factor indicators
        st.subheader("üìä Risk Factor Analysis")
        
        # Heart rate assessment
        if heart_rate > 100:
            st.warning("‚ö†Ô∏è Elevated heart rate detected")
        elif heart_rate < 60:
            st.info("‚ÑπÔ∏è Low heart rate - possible athlete or condition")
        else:
            st.success("‚úÖ Normal heart rate range")
        
        # Activity assessment
        if steps_daily < 5000:
            st.warning("‚ö†Ô∏è Low activity level")
        elif steps_daily > 12000:
            st.success("‚úÖ High activity level")
        else:
            st.info("‚ÑπÔ∏è Moderate activity level")
    
    with col2:
        st.subheader("Prediction Results")
        
        if submitted:
            # Prepare data
            data = {
                "heart_rate": heart_rate,
                "steps_daily": steps_daily,
                "sleep_hours": sleep_hours,
                "age": age
            }
            
            try:
                # Call API
                response = requests.post("http://localhost:8000/predict", json=data, timeout=10)
                
                if response.status_code == 200:
                    result = response.json()
                    
                    # Risk level display
                    risk_level = result["risk_level"]
                    probability = result["probability"]
                    confidence = result["confidence"]
                    
                    if risk_level == "High Risk":
                        st.error(f"‚ö†Ô∏è **{risk_level}**")
                    else:
                        st.success(f"‚úÖ **{risk_level}**")
                    
                    # Metrics
                    col_a, col_b, col_c = st.columns(3)
                    with col_a:
                        st.metric("Risk Probability", f"{probability:.1%}")
                    with col_b:
                        st.metric("Confidence", confidence)
                    with col_c:
                        timestamp = datetime.fromisoformat(result["timestamp"].replace('Z', '+00:00'))
                        st.metric("Prediction Time", timestamp.strftime("%H:%M:%S"))
                    
                    # Risk gauge
                    fig = go.Figure(go.Indicator(
                        mode = "gauge+number+delta",
                        value = probability * 100,
                        domain = {'x': [0, 1], 'y': [0, 1]},
                        title = {'text': "Risk Level (%)"},
                        delta = {'reference': 50},
                        gauge = {
                            'axis': {'range': [None, 100]},
                            'bar': {'color': "red" if probability > 0.5 else "green"},
                            'steps': [
                                {'range': [0, 25], 'color': "lightgreen"},
                                {'range': [25, 50], 'color': "yellow"},
                                {'range': [50, 75], 'color': "orange"},
                                {'range': [75, 100], 'color': "red"}
                            ],
                            'threshold': {
                                'line': {'color': "red", 'width': 4},
                                'thickness': 0.75,
                                'value': 90
                            }
                        }
                    ))
                    fig.update_layout(height=300)
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # Recommendations
                    st.subheader("üí° Recommendations")
                    for i, rec in enumerate(result["recommendations"], 1):
                        st.write(f"{i}. {rec}")
                
                else:
                    st.error("‚ùå API Error - Check server status")
                    
            except requests.exceptions.RequestException:
                st.error("‚ùå Cannot connect to API server")
                st.info("üí° Make sure to run: `python enhanced_api.py`")

def data_analysis_page():
    st.header("üìä Health Data Analysis")
    
    if st.button("Generate Sample Dataset"):
        # Generate sample data locally
        with st.spinner("Generating health data..."):
            df = generate_sample_data()
        
        # Store in session state
        st.session_state['health_data'] = df
        st.success(f"‚úÖ Generated {len(df)} health records")
    
    if 'health_data' in st.session_state:
        df = st.session_state['health_data']
        
        # Dataset overview
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Total Records", len(df))
        with col2:
            st.metric("High Risk Cases", df['high_risk'].sum())
        with col3:
            st.metric("Risk Rate", f"{df['high_risk'].mean():.1%}")
        with col4:
            st.metric("Avg Age", f"{df['age'].mean():.0f}")
        
        # Data visualizations
        st.subheader("üìà Data Distribution Analysis")
        
        # Create subplot layout
        col1, col2 = st.columns(2)
        
        with col1:
            # Heart rate distribution by risk
            fig1 = px.histogram(
                df, x="heart_rate", color="high_risk", 
                title="Heart Rate Distribution by Risk Level",
                nbins=30, opacity=0.7
            )
            fig1.update_layout(height=400)
            st.plotly_chart(fig1, use_container_width=True)
            
            # Steps vs Sleep correlation
            fig3 = px.scatter(
                df, x="steps_daily", y="sleep_hours", 
                color="high_risk", size="age",
                title="Daily Steps vs Sleep Hours",
                hover_data=['heart_rate', 'age']
            )
            fig3.update_layout(height=400)
            st.plotly_chart(fig3, use_container_width=True)
        
        with col2:
            # Age distribution
            fig2 = px.box(
                df, x="high_risk", y="age", 
                title="Age Distribution by Risk Level"
            )
            fig2.update_layout(height=400)
            st.plotly_chart(fig2, use_container_width=True)
            
            # Feature correlation heatmap
            corr_data = df[['heart_rate', 'steps_daily', 'sleep_hours', 'age', 'risk_score']].corr()
            fig4 = px.imshow(
                corr_data, text_auto=True, aspect="auto",
                title="Feature Correlation Matrix"
            )
            fig4.update_layout(height=400)
            st.plotly_chart(fig4, use_container_width=True)
        
        # Risk factors analysis
        st.subheader("üéØ Risk Factor Analysis")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            high_hr = (df['heart_rate'] > 100).sum()
            st.metric("High Heart Rate Cases", high_hr, f"{high_hr/len(df):.1%}")
        
        with col2:
            low_activity = (df['steps_daily'] < 5000).sum()
            st.metric("Low Activity Cases", low_activity, f"{low_activity/len(df):.1%}")
        
        with col3:
            poor_sleep = (df['sleep_hours'] < 6).sum()
            st.metric("Poor Sleep Cases", poor_sleep, f"{poor_sleep/len(df):.1%}")
        
        # Data table
        st.subheader("üìã Sample Data")
        st.dataframe(df.head(20), use_container_width=True)

def generate_sample_data():
    """Generate sample health data for demo"""
    np.random.seed(42)
    n = 1000
    
    # Generate realistic health data
    ages = np.random.randint(18, 80, n)
    
    # Heart rate depends on age and fitness
    base_hr = 220 - ages  # Max HR formula
    resting_hr = np.random.normal(70, 12, n) + (ages - 40) * 0.2
    heart_rate = np.clip(resting_hr, 45, 120)
    
    # Steps depend on age and lifestyle
    base_steps = np.random.normal(8000, 3000, n) - (ages - 30) * 20
    steps_daily = np.clip(base_steps, 1000, 25000)
    
    # Sleep patterns
    sleep_hours = np.random.normal(7.5, 1.2, n)
    sleep_hours = np.clip(sleep_hours, 4, 11)
    
    # Calculate risk
    hr_risk = np.where(heart_rate > 100, 1.0, np.where(heart_rate < 60, 0.7, 0.0))
    activity_risk = np.where(steps_daily < 5000, 0.8, np.where(steps_daily < 3000, 1.0, 0.0))
    sleep_risk = np.where(sleep_hours < 6, 0.7, np.where(sleep_hours < 5, 1.0, 0.0))
    age_risk = np.where(ages > 65, 0.6, np.where(ages > 75, 0.8, 0.0))
    
    # Weighted risk score
    weights = {'hr': 0.35, 'activity': 0.25, 'sleep': 0.25, 'age': 0.15}
    risk_score = (
        hr_risk * weights['hr'] + 
        activity_risk * weights['activity'] + 
        sleep_risk * weights['sleep'] + 
        age_risk * weights['age']
    )
    
    # Add noise and create binary risk
    noise = np.random.normal(0, 0.1, len(risk_score))
    risk_score = np.clip(risk_score + noise, 0, 1)
    high_risk = (risk_score > 0.4).astype(int)
    
    df = pd.DataFrame({
        'heart_rate': heart_rate.round(0),
        'steps_daily': steps_daily.round(0),
        'sleep_hours': sleep_hours.round(1),
        'age': ages,
        'risk_score': risk_score,
        'high_risk': high_risk
    })
    
    return df

def model_performance_page():
    st.header("üìà Model Performance Analysis")
    
    try:
        # Load model metadata
        with open('models/model_metadata.json', 'r') as f:
            metadata = json.load(f)
        
        # Performance metrics
        st.subheader("üéØ Model Metrics")
        
        metrics = metadata['metrics']
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Accuracy", f"{metrics['accuracy']:.3f}", 
                     delta=f"{np.random.uniform(-0.02, 0.02):.3f}")
        with col2:
            st.metric("Precision", f"{metrics['precision']:.3f}",
                     delta=f"{np.random.uniform(-0.02, 0.02):.3f}")
        with col3:
            st.metric("Recall", f"{metrics['recall']:.3f}",
                     delta=f"{np.random.uniform(-0.02, 0.02):.3f}")
        with col4:
            st.metric("F1-Score", f"{metrics['f1_score']:.3f}",
                     delta=f"{np.random.uniform(-0.02, 0.02):.3f}")
        
        # Additional metrics
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ROC-AUC", f"{metrics['roc_auc']:.3f}")
        with col2:
            st.metric("Specificity", f"{metrics['specificity']:.3f}")
        with col3:
            st.metric("Training Time", f"{metrics['training_time']:.2f}s")
        
        # Model configuration
        st.subheader("‚öôÔ∏è Model Configuration")
        
        config_col1, config_col2 = st.columns(2)
        
        with config_col1:
            st.info("**Model Type:** Random Forest Classifier")
            st.info(f"**Features:** {len(metadata['features'])}")
            st.info(f"**N Estimators:** {metadata['config']['n_estimators']}")
        
        with config_col2:
            st.info(f"**Max Depth:** {metadata['config']['max_depth']}")
            st.info(f"**Random State:** {metadata['config']['random_state']}")
            st.info(f"**Last Trained:** {metadata['timestamp'][:16]}")
        
        # Feature importance (simulated)
        st.subheader("üéØ Feature Importance")
        
        # Create simulated feature importance
        feature_names = metadata['features']
        importance_values = [0.35, 0.28, 0.22, 0.15]  # Simulated values
        
        importance_data = pd.DataFrame({
            'Feature': feature_names,
            'Importance': importance_values
        }).sort_values('Importance', ascending=True)
        
        fig = px.bar(
            importance_data, x='Importance', y='Feature',
            orientation='h', title="Feature Importance Ranking"
        )
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
        
        # Performance over time (simulated)
        st.subheader("üìä Performance Trends")
        
        # Generate simulated performance data
        dates = pd.date_range(start='2024-01-01', periods=30, freq='D')
        performance_data = pd.DataFrame({
            'Date': dates,
            'Accuracy': np.random.normal(0.85, 0.02, 30),
            'Precision': np.random.normal(0.82, 0.025, 30),
            'Recall': np.random.normal(0.88, 0.02, 30)
        })
        
        fig = px.line(
            performance_data, x='Date', 
            y=['Accuracy', 'Precision', 'Recall'],
            title="Model Performance Over Time"
        )
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
        
    except FileNotFoundError:
        st.warning("‚ö†Ô∏è Model metadata not found. Train the model first!")
        if st.button("üöÄ Train Model Now"):
            st.info("Run: `python enhanced_training.py`")

def mlops_pipeline_page():
    st.header("üöÄ MLOps Pipeline Overview")
    
    # Pipeline stages
    st.subheader("üîÑ Pipeline Stages")
    
    stages = [
        ("1Ô∏è‚É£", "Data Generation", "Synthetic health data creation", "‚úÖ Complete"),
        ("2Ô∏è‚É£", "Feature Engineering", "Health metrics processing", "‚úÖ Complete"),
        ("3Ô∏è‚É£", "Model Training", "RandomForest with validation", "‚úÖ Complete"),
        ("4Ô∏è‚É£", "Model Validation", "Performance evaluation", "‚úÖ Complete"),
        ("5Ô∏è‚É£", "Model Deployment", "API endpoint creation", "‚úÖ Complete"),
        ("6Ô∏è‚É£", "Monitoring", "Performance tracking", "üîÑ Active"),
    ]
    
    for icon, stage, description, status in stages:
        col1, col2, col3, col4 = st.columns([1, 3, 4, 2])
        with col1:
            st.write(icon)
        with col2:
            st.write(f"**{stage}**")
        with col3:
            st.write(description)
        with col4:
            st.write(status)
    
    st.markdown("---")
    
    # MLOps capabilities
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üîß MLOps Capabilities")
        
        capabilities = [
            "‚úÖ Automated data pipeline",
            "‚úÖ Model versioning with MLflow",
            "‚úÖ Experiment tracking",
            "‚úÖ Model validation & testing",
            "‚úÖ API deployment",
            "‚úÖ Real-time monitoring",
            "‚úÖ Performance logging",
            "‚úÖ Health checks"
        ]
        
        for capability in capabilities:
            st.write(capability)
    
    with col2:
        st.subheader("üìä System Architecture")
        
        # Create a simple architecture diagram
        architecture_data = {
            'Component': ['Data Pipeline', 'ML Training', 'Model Registry', 'API Server', 'Dashboard', 'Monitoring'],
            'Status': ['Active', 'Complete', 'Active', 'Running', 'Running', 'Active'],
            'Technology': ['Python/Pandas', 'Scikit-learn', 'MLflow', 'FastAPI', 'Streamlit', 'Custom']
        }
        
        arch_df = pd.DataFrame(architecture_data)
        st.dataframe(arch_df, use_container_width=True)
    
    # Command reference
    st.subheader("‚ö° Quick Commands")
    
    commands = {
        "Train Model": "python enhanced_training.py",
        "Start API": "python enhanced_api.py",
        "Launch Dashboard": "streamlit run enhanced_dashboard.py",
        "View Experiments": "mlflow ui",
        "Check API Health": "curl http://localhost:8000/health"
    }
    
    for desc, cmd in commands.items():
        st.code(f"# {desc}\n{cmd}")

def system_monitoring_page():
    st.header("üìã System Monitoring & Health")
    
    # API Health Check
    st.subheader("üåê API Health Status")
    
    try:
        response = requests.get("http://localhost:8000/health", timeout=5)
        if response.status_code == 200:
            health_data = response.json()
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.success("üü¢ API Status: Online")
            with col2:
                st.metric("Predictions Served", health_data.get('predictions_served', 0))
            with col3:
                st.info(f"Last Check: {health_data.get('timestamp', 'N/A')[:16]}")
            
            # Get model info
            try:
                model_response = requests.get("http://localhost:8000/model/info", timeout=5)
                if model_response.status_code == 200:
                    model_info = model_response.json()
                    
                    st.subheader("ü§ñ Model Information")
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.info(f"**Type:** {model_info['model_type']}")
                        st.info(f"**Version:** {model_info['version']}")
                    
                    with col2:
                        st.info(f"**Features:** {len(model_info['features'])}")
                        st.info(f"**Accuracy:** {model_info['metrics']['accuracy']:.3f}")
                    
                    with col3:
                        st.info(f"**Last Trained:** {model_info['last_trained'][:16]}")
                        st.info(f"**F1-Score:** {model_info['metrics']['f1_score']:.3f}")
            
            except:
                st.warning("Could not fetch model information")
        
        else:
            st.error("üî¥ API Status: Error")
    
    except:
        st.error("üî¥ API Status: Offline")
        st.info("üí° Start the API server: `python enhanced_api.py`")
    
    # System metrics (simulated)
    st.subheader("üìä System Performance")
    
    # Generate simulated metrics
    cpu_usage = np.random.uniform(20, 80)
    memory_usage = np.random.uniform(30, 70)
    disk_usage = np.random.uniform(40, 60)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("CPU Usage", f"{cpu_usage:.1f}%", 
                 delta=f"{np.random.uniform(-5, 5):.1f}%")
    
    with col2:
        st.metric("Memory Usage", f"{memory_usage:.1f}%",
                 delta=f"{np.random.uniform(-3, 3):.1f}%")
    
    with col3:
        st.metric("Disk Usage", f"{disk_usage:.1f}%",
                 delta=f"{np.random.uniform(-1, 1):.1f}%")
    
    # Response time chart (simulated)
    st.subheader("‚ö° API Response Times")
    
    # Generate simulated response time data
    times = pd.date_range(start=datetime.now()-timedelta(hours=24), 
                         periods=100, freq='15min')
    response_times = np.random.gamma(2, 50, 100)  # Realistic response times
    
    response_df = pd.DataFrame({
        'Time': times,
        'Response Time (ms)': response_times
    })
    
    fig = px.line(response_df, x='Time', y='Response Time (ms)',
                 title="API Response Time (Last 24h)")
    fig.add_hline(y=100, line_dash="dash", line_color="red", 
                 annotation_text="SLA Threshold")
    fig.update_layout(height=400)
    st.plotly_chart(fig, use_container_width=True)
    
    # Error rate monitoring
    st.subheader("üö® Error Monitoring")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Simulated error data
        error_rate = np.random.uniform(0, 2)  # 0-2% error rate
        st.metric("Error Rate", f"{error_rate:.2f}%",
                 delta=f"{np.random.uniform(-0.5, 0.5):.2f}%")
        
        if error_rate > 1:
            st.warning("‚ö†Ô∏è Error rate above threshold!")
        else:
            st.success("‚úÖ Error rate within normal range")
    
    with col2:
        # Recent errors (simulated)
        recent_errors = pd.DataFrame({
            'Timestamp': pd.date_range(start=datetime.now()-timedelta(hours=6), 
                                     periods=3, freq='2h'),
            'Error Type': ['Validation Error', 'Timeout', 'Model Error'],
            'Count': [2, 1, 1]
        })
        
        st.dataframe(recent_errors, use_container_width=True)
    
    # Model drift monitoring
    st.subheader("üìà Model Drift Detection")
    
    # Simulated drift metrics
    drift_score = np.random.uniform(0, 0.3)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.metric("Drift Score", f"{drift_score:.3f}")
        
        if drift_score > 0.2:
            st.warning("‚ö†Ô∏è Potential model drift detected")
            st.info("üí° Consider retraining the model")
        else:
            st.success("‚úÖ Model performance stable")
    
    with col2:
        # Feature drift chart
        features = ['heart_rate', 'steps_daily', 'sleep_hours', 'age']
        drift_values = np.random.uniform(0, 0.4, len(features))
        
        drift_df = pd.DataFrame({
            'Feature': features,
            'Drift Score': drift_values
        })
        
        fig = px.bar(drift_df, x='Feature', y='Drift Score',
                    title="Feature Drift Scores")
        fig.add_hline(y=0.2, line_dash="dash", line_color="red")
        fig.update_layout(height=300)
        st.plotly_chart(fig, use_container_width=True)

if __name__ == "__main__":
    main()